{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "525c023c",
   "metadata": {},
   "source": [
    "# AutoPrepML Demo Notebook\n",
    "\n",
    "This notebook demonstrates the core functionality of AutoPrepML using the Titanic dataset.\n",
    "\n",
    "## Features Demonstrated:\n",
    "- Data loading and inspection\n",
    "- Automatic issue detection\n",
    "- Data cleaning and preprocessing\n",
    "- Report generation\n",
    "- Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e87239",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "# Install AutoPrepML (if not already installed)\n",
    "# !pip install autoprepml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autoprepml import AutoPrepML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1970fad",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Dataset\n",
    "\n",
    "We'll create a sample Titanic-like dataset with common data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf7a40",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "# Create a sample Titanic-like dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "data = {\n",
    "    'PassengerId': range(1, 101),\n",
    "    'Survived': np.random.choice([0, 1], 100, p=[0.6, 0.4]),\n",
    "    'Pclass': np.random.choice([1, 2, 3], 100, p=[0.2, 0.3, 0.5]),\n",
    "    'Age': np.random.normal(30, 15, 100),\n",
    "    'SibSp': np.random.poisson(0.5, 100),\n",
    "    'Parch': np.random.poisson(0.3, 100),\n",
    "    'Fare': np.random.lognormal(3, 1, 100),\n",
    "    'Sex': np.random.choice(['male', 'female'], 100, p=[0.65, 0.35]),\n",
    "    'Embarked': np.random.choice(['S', 'C', 'Q'], 100, p=[0.7, 0.2, 0.1])\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add missing values\n",
    "df.loc[df.sample(frac=0.2).index, 'Age'] = np.nan\n",
    "df.loc[df.sample(frac=0.15).index, 'Embarked'] = np.nan\n",
    "df.loc[df.sample(frac=0.05).index, 'Fare'] = np.nan\n",
    "\n",
    "# Add outliers\n",
    "df.loc[0, 'Fare'] = 1000.0\n",
    "df.loc[1, 'Age'] = 150.0\n",
    "\n",
    "print(\"Dataset created!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921b88e",
   "metadata": {},
   "source": [
    "## 2. Initialize AutoPrepML\n",
    "\n",
    "Create an AutoPrepML instance with your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8d4da3",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize AutoPrepML\n",
    "prep = AutoPrepML(df)\n",
    "\n",
    "# Get a quick summary\n",
    "summary = prep.summary()\n",
    "\n",
    "print(\"üìä Dataset Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {summary['shape']}\")\n",
    "print(f\"Numeric columns: {summary['numeric_columns']}\")\n",
    "print(f\"Categorical columns: {summary['categorical_columns']}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "for col, info in summary['missing_values'].items():\n",
    "    print(f\"  - {col}: {info['count']} ({info['percent']}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1705cf",
   "metadata": {},
   "source": [
    "## 3. Detect Data Issues\n",
    "\n",
    "Run detection to identify missing values, outliers, and class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4484eb2b",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "# Run detection\n",
    "detection_results = prep.detect(target_col='Survived')\n",
    "\n",
    "print(\"üîç Detection Results\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Missing values\n",
    "print(f\"\\nüìå Missing Values: {len(detection_results['missing_values'])} columns affected\")\n",
    "for col, info in detection_results['missing_values'].items():\n",
    "    print(f\"  - {col}: {info['count']} missing ({info['percent']}%)\")\n",
    "\n",
    "# Outliers\n",
    "outliers = detection_results['outliers']\n",
    "print(f\"\\nüìå Outliers: {outliers['outlier_count']} detected using {outliers['method']}\")\n",
    "\n",
    "# Class imbalance\n",
    "if 'class_imbalance' in detection_results:\n",
    "    imbalance = detection_results['class_imbalance']\n",
    "    print(f\"\\nüìå Class Balance:\")\n",
    "    print(f\"  - Target: {imbalance['target_column']}\")\n",
    "    print(f\"  - Is imbalanced: {imbalance['is_imbalanced']}\")\n",
    "    print(f\"  - Distribution: {imbalance['class_distribution']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bfa7a",
   "metadata": {},
   "source": [
    "## 4. Clean the Data\n",
    "\n",
    "Apply automatic cleaning based on detected issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91459c",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "# Clean the dataset\n",
    "clean_df, report = prep.clean(task='classification', target_col='Survived')\n",
    "\n",
    "print(\"üßπ Cleaning Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {clean_df.shape}\")\n",
    "print(f\"Missing values remaining: {clean_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Show first few rows of cleaned data\n",
    "print(\"\\n‚úÖ Cleaned Data Sample:\")\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d87c14",
   "metadata": {},
   "source": [
    "## 5. Review the Report\n",
    "\n",
    "The report contains detailed information about all preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c430228",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "# Examine the report\n",
    "print(\"üìÑ Preprocessing Report\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Timestamp: {report['timestamp']}\")\n",
    "print(f\"Original shape: {report['original_shape']}\")\n",
    "print(f\"Cleaned shape: {report['cleaned_shape']}\")\n",
    "\n",
    "print(\"\\nüîß Processing Steps:\")\n",
    "for i, log_entry in enumerate(report['logs'][-5:], 1):  # Last 5 steps\n",
    "    print(f\"{i}. {log_entry['action']}: {log_entry['details']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1704d858",
   "metadata": {},
   "source": [
    "## 6. Save Results\n",
    "\n",
    "Save the cleaned dataset and generate HTML report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1366a",
   "metadata": {
    "vscode": {
     "languageId": "code"
    }
   },
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "clean_df.to_csv('titanic_cleaned.csv', index=False)\n",
    "\n",
    "# Save HTML report\n",
    "prep.save_report('titanic_report.html')\n",
    "\n",
    "print(\"‚úÖ Results saved!\")\n",
    "print(\"  - Cleaned data: titanic_cleaned.csv\")\n",
    "print(\"  - Report: titanic_report.html\")\n",
    "print(\"\\nüí° Open titanic_report.html in a browser to see visualizations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19955b7a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. ‚úÖ Created a sample dataset with missing values and outliers\n",
    "2. ‚úÖ Initialized AutoPrepML\n",
    "3. ‚úÖ Detected data quality issues\n",
    "4. ‚úÖ Automatically cleaned the data\n",
    "5. ‚úÖ Generated comprehensive reports\n",
    "6. ‚úÖ Saved results for further analysis\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try AutoPrepML on your own datasets\n",
    "- Customize preprocessing with config files\n",
    "- Explore the HTML report visualizations\n",
    "- Use the CLI for batch processing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
